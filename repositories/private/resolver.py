# Copyright 2022 Milan Vukov
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import argparse
import asyncio
import logging
import os
import pathlib
import string
import sys
import tempfile
import urllib

import aiofile
import aiohttp
import tqdm.asyncio
import yaml


def is_github_url(url):
    url_info = urllib.parse.urlparse(url)
    return url_info.netloc == 'github.com'


def is_gitlab_url(url):
    url_info = urllib.parse.urlparse(url)
    return url_info.netloc == 'gitlab.com'


def get_gitlab_project_name(url):
    url_info = urllib.parse.urlparse(url)
    return url_info.path.split('/')[-1]


def create_archive_name(name, url):
    url_info = urllib.parse.urlparse(url)
    archive_name = url_info.path.split('/')[-1]
    if archive_name.startswith(name):
        return archive_name
    return f'{name}-{archive_name}'


async def compute_sha_sum(file):
    sha256sum_process = await asyncio.create_subprocess_shell(
        f'sha256sum {file}',
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE)
    await sha256sum_process.wait()
    if sha256sum_process.returncode:
        logging.error(f'Failed to calculate SHA256 sum for {file}!')
        return None
    stdout = await sha256sum_process.stdout.read()
    return stdout.decode('utf-8').split(' ')[0]


async def download_urls_and_compute_sha_sums(names_to_urls, outputs_dir):
    semaphore = asyncio.BoundedSemaphore(5)

    async def download_url_and_compute_sha_sum(name, url, session):
        async with semaphore:
            async with session.get(url) as response:
                if response.status != 200:
                    logging.error(f'Failed to fetch {url}: {response.reason}')
                    return name, None
                data = await response.read()

            output_file = outputs_dir / create_archive_name(name, url)
            async with aiofile.async_open(output_file, 'wb') as stream:
                await stream.write(data)

            return name, await compute_sha_sum(output_file)

    async with aiohttp.ClientSession() as session:
        tasks = [
            asyncio.create_task(
                download_url_and_compute_sha_sum(name, url, session))
            for name, url in names_to_urls.items()
        ]
        names_and_data = [
            await f for f in tqdm.asyncio.tqdm.as_completed(
                tasks, desc='Downloading archives and calculating SHA sums')
        ]
        return dict(names_and_data)


HTTP_ARCHIVE_TEMPLATE = """\
    maybe(
        http_archive,
{args}
    )
"""

BZL_TEMPLATE = """\
# This file is automatically generated.
load("@bazel_tools//tools/build_defs/repo:http.bzl", "http_archive")
load("@bazel_tools//tools/build_defs/repo:utils.bzl", "maybe")

def ros2_repositories_impl():
{http_archives}
"""


def dump_http_archives(repos):
    http_archives = []
    for repo in repos:
        http_archive_args = []
        for key, value in repo.items():
            if isinstance(value, str):
                http_archive_args.append(' ' * 8 + f'{key} = "{value}",')
            elif isinstance(value, list):
                value_str = ', '.join([f'"{v}"' for v in value])
                http_archive_args.append(' ' * 8 + f'{key} = [{value_str}],')
            else:
                sys.exit(f'Cannot handle {value} for {key}!')
        http_archives.append(
            HTTP_ARCHIVE_TEMPLATE.format(args='\n'.join(http_archive_args)))
    return BZL_TEMPLATE.format(
        http_archives='\n'.join(http_archives)).rstrip() + '\n'


def is_git_hash(version: str) -> bool:
    """Check if version is a full length SHA-1 (git) hash."""
    return len(version) == 40 and set(version).issubset(string.hexdigits)


def main():
    if 'BUILD_WORKSPACE_DIRECTORY' not in os.environ:
        sys.exit("""
Please run this app as a Bazel target
bazel run //repositories/private:resolver
        """)

    parser = argparse.ArgumentParser()
    parser.add_argument('--repos', type=str)
    parser.add_argument('--repo_mappings', type=str)
    parser.add_argument('--output', type=str)
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO)

    with open(args.repos, encoding='utf-8') as stream:
        repos = yaml.load(stream, Loader=yaml.Loader)['repositories']
    with open(args.repo_mappings, encoding='utf-8') as stream:
        repo_mappings = yaml.load(stream, Loader=yaml.Loader)['repositories']

    all_repos_ok = all([info['type'] == 'git' for info in repos.values()])
    if not all_repos_ok:
        sys.exit('Type of all repositories must be `git`!')

    requested_repos = repo_mappings.keys()
    names_to_urls = {}
    names_to_versions = {}
    suffix_len = len('.git')
    for name, info in repos.items():
        url = info['url'][:-suffix_len]
        version = info['version']
        if is_github_url(url):
            ref = version if is_git_hash(version) else f'refs/tags/{version}'
            archive_url = f'{url}/archive/{ref}.tar.gz'
        elif is_gitlab_url(url):
            archive_url = (f'{url}/-/archive/{version}/'
                           f'{get_gitlab_project_name(url)}-{version}.tar.gz')
        else:
            sys.exit(f'{name}: URL must be github/gitlab hosted, got `{url}`!')

        project_name = name.split('/')[-1]
        if project_name not in requested_repos:
            continue
        names_to_urls[project_name] = archive_url
        names_to_versions[project_name] = version

    with tempfile.TemporaryDirectory() as tmp_dir_name:
        names_to_sha_sums = asyncio.run(
            download_urls_and_compute_sha_sums(names_to_urls,
                                               pathlib.Path(tmp_dir_name)))

    for name, sha_sum in names_to_sha_sums.items():
        repo_mappings[name]['sha256'] = sha_sum
    for name, version in names_to_versions.items():
        if 'strip_prefix' not in repo_mappings[name].keys():
            repo_mappings[name]['strip_prefix'] = f'{name}-{version}'
    for name, url in names_to_urls.items():
        repo_mappings[name]['url'] = url

    with open(args.output, 'w', encoding='utf-8') as stream:
        stream.write(dump_http_archives(repo_mappings.values()))


if __name__ == '__main__':
    main()
